{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Yu45OYdj3Y"
      },
      "source": [
        "# Day 9 Lab, IS 4487\n",
        "\n",
        "What do you need to do for today's project?\n",
        "\n",
        "1. Use the model to predict on a new dataset (without the target), then use those predictions to identify those who should be called--a contact list.\n",
        "2.  Make a recommendation to the Director of Sales based on all of your analytic work for this project.\n",
        "\n",
        "Remember that for this example we'll be using the MegaTelCo data, where the target is `leave` not `answer`.  \n",
        "\n",
        "Note that the first set of steps below is identical to the workflow in previous labs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE93RwXhgiJS"
      },
      "source": [
        "#Load Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYRZY5n0gfNe"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz # Import Decision Tree Classifier\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bREaXo8jfu-O"
      },
      "source": [
        "# Get Data\n",
        "\n",
        "For this part of the project we will be using the model to predict whether *current* customers will churn.\n",
        "\n",
        "Remember:  we have trained the model on historical data, which includes information about whether customers have *already* churned.  But the important use case is to predict whether *current* customers will churn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udYgkb6I3SJo"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "mtc = pd.read_csv(\"https://raw.githubusercontent.com/jefftwebb/is_4487_base/dd870389117d5b24eee7417d5378d80496555130/Labs/DataSets/megatelco_leave_survey.csv\")\n",
        "\n",
        "# Current customer data\n",
        "current_customers = pd.read_csv(\"https://raw.githubusercontent.com/jefftwebb/is_4487_base/main/Labs/DataSets/megatelco_new_customer_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should double check that this new dataset is also clean.  If it isn't there will be problems when predicting."
      ],
      "metadata": {
        "id": "rMmhoARH027w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_customers.describe()"
      ],
      "metadata": {
        "id": "2TCXNZDM02RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_customers.info()"
      ],
      "metadata": {
        "id": "NUEOzTt61KeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks okay.\n",
        "\n",
        "And note that there is no target variable in the data."
      ],
      "metadata": {
        "id": "xR49h5BJ1Hbf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxOWvFlKzgE"
      },
      "source": [
        "# Clean data\n",
        "\n",
        "We need to take care that we perform *exactly* the same cleaning on the new data.\n",
        "\n",
        "Here is the cleaning/preparation for the historical MegaTelco data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KXLvMcBK8Za"
      },
      "outputs": [],
      "source": [
        "# Make explicit copy\n",
        "mtc_clean = mtc.copy()\n",
        "\n",
        "# filter rows\n",
        "mtc_clean = mtc_clean[(mtc_clean['house'] > 0) & (mtc_clean['income'] > 0) & (mtc_clean['handset_price'] < 1000)]\n",
        "\n",
        "# remove NAs\n",
        "mtc_clean = mtc_clean.dropna()\n",
        "\n",
        "# Recode college\n",
        "mtc_clean['college'] = mtc_clean['college'].replace({'one': 'yes', 'zero': 'no'})\n",
        "\n",
        "# change reported usage and reported satisfaction (ordered)\n",
        "mtc_clean['college'] = pd.Categorical(mtc_clean['college'],\n",
        "                                    ordered = False).codes\n",
        "\n",
        "mtc_clean['considering_change_of_plan'] = pd.Categorical(mtc_clean['considering_change_of_plan'],\n",
        "                                    ordered = False).codes\n",
        "\n",
        "# change reported usage and reported satisfaction (ordered)\n",
        "mtc_clean['reported_usage_level'] = pd.Categorical(mtc_clean['reported_usage_level'],\n",
        "                                    categories = ['low', 'avg','high'],\n",
        "                                    ordered = True).codes\n",
        "\n",
        "mtc_clean['reported_satisfaction'] = pd.Categorical(mtc_clean['reported_satisfaction'],\n",
        "                                    categories = ['low', 'avg','high'],\n",
        "                                    ordered = True).codes\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And here is that same cleaning applied the data on current customers:"
      ],
      "metadata": {
        "id": "QtLvsCCUVKoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make explicit copy: ccc refers to current customers clean\n",
        "ccc = current_customers.copy()\n",
        "\n",
        "# filter rows\n",
        "ccc = ccc[(ccc['house'] > 0) & (ccc['income'] > 0) & (ccc['handset_price'] < 1000)]\n",
        "\n",
        "# remove NAs\n",
        "ccc = ccc.dropna()\n",
        "\n",
        "# Recode college\n",
        "ccc['college'] = ccc['college'].replace({'one': 'yes', 'zero': 'no'})\n",
        "\n",
        "# change reported usage and reported satisfaction (ordered)\n",
        "ccc['college'] = pd.Categorical(ccc['college'],\n",
        "                                    ordered = False).codes\n",
        "\n",
        "ccc['considering_change_of_plan'] = pd.Categorical(ccc['considering_change_of_plan'],\n",
        "                                    ordered = False).codes\n",
        "\n",
        "# change reported usage and reported satisfaction (ordered)\n",
        "ccc['reported_usage_level'] = pd.Categorical(ccc['reported_usage_level'],\n",
        "                                    categories = ['low', 'avg','high'],\n",
        "                                    ordered = True).codes\n",
        "\n",
        "ccc['reported_satisfaction'] = pd.Categorical(ccc['reported_satisfaction'],\n",
        "                                    categories = ['low', 'avg','high'],\n",
        "                                    ordered = True).codes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R2841HpyVSQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp7wGDqJ4iuL"
      },
      "source": [
        "# Fit full model\n",
        "\n",
        "Again, we will set `max_depth = 5` to keep the tree simple and prevent overfitting.\n",
        "\n",
        "Since we have already determined that the model is not overfitting the data we can dispense with splitting it into train and test sets.  We will therefore use *all* the data to fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvMekcKg4y5X"
      },
      "outputs": [],
      "source": [
        "# split the dataframe into predictors (X) and target (y)\n",
        "X = mtc_clean.drop(['id', 'leave'], axis=1)\n",
        "y = mtc_clean['leave']\n",
        "\n",
        "# initialize the tree\n",
        "full_tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 5)\n",
        "\n",
        "# Create Decision Tree Classifer\n",
        "full_tree = full_tree.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict\n",
        "\n",
        "The next step is to use the model to predict churn for the current customers.\n",
        "\n",
        "We need to ensure that the new dataset has the same shape and data types  as the data used to fit the model."
      ],
      "metadata": {
        "id": "lQqezQ9a1WtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will entail dropping the `id` column."
      ],
      "metadata": {
        "id": "ZC0RmbY92Nlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = ccc.drop(['id'], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ipxHmR8e16g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we predict the probability of churn using the new data. Remember:  we are using the model trained on the historical data, `full_model`, to predict for the new data, `ccc` (the clean current customers data).\n",
        "\n",
        "The `predict_proba()` function returns an array with two columns that are organized according to the levels in the target:  column 0 presents the probability of `LEAVE` (the first level in the target); column 1 presents the probability of `STAY` (the second level).\n",
        "\n",
        "Hence we need to index that array to obtain the probabilities for `LEAVE` by choosing the first column: `[:, 0]`"
      ],
      "metadata": {
        "id": "_pIrr_Jf27Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "zBk-RMeC1mJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I66jKusS_Xe"
      },
      "source": [
        "# Add predictions to the data\n",
        "\n",
        "The next step is to append the predictions to the `current_customers` data so we can link the predictions to the customer ID.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here to create the contact list\n"
      ],
      "metadata": {
        "id": "e9dM5wVV3u_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Which customers to target for retention?\n",
        "\n",
        "This is a contact list that can be handed off to the marketing department to direct their retention efforts!\n",
        "\n",
        "We need to organize the list by first sorting it then filtering it to include only customers with a predicted probability of churning greater than .2.  For sorting we'll use the Pandas function, `sort_values`:"
      ],
      "metadata": {
        "id": "Vf7aJojy4pCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here to sort the list and filter for probabilities > .2\n"
      ],
      "metadata": {
        "id": "gZ-HFqkWbQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many customer are on the contact list?"
      ],
      "metadata": {
        "id": "XeuLC-qgb8LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "nfPDKwBsb_nA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}