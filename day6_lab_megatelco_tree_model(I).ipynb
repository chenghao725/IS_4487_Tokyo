{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Yu45OYdj3Y"
      },
      "source": [
        "# Day 6 Lab, IS 4487\n",
        "\n",
        "The purpose of this lab is to prepare you to complete today's project quiz. Here are the questions you need to be able to answer.\n",
        "\n",
        "- Understand model accuracy.  And:  Why is it a performance metric for classification and not regression?\n",
        "- Calculate accuracy for a simple majority class model (this is the same as calculating the proportion of the majority class in a binary variable).\n",
        "- Fit a tree model of the target with just one predictor variable and calculate the accuracy of this model.\n",
        "- Calculate accuracy for the tree model.\n",
        "- Explain how the classification tree algorithm chooses which variable to split on and where to split.\n",
        "\n",
        "Additionally will talk about cross validation and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE93RwXhgiJS"
      },
      "source": [
        "## Load Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYRZY5n0gfNe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Import packages needed for the classification tree\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz # Import Decision Tree Classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bREaXo8jfu-O"
      },
      "source": [
        "## Get Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "O8P7DoGU3aG8"
      },
      "outputs": [],
      "source": [
        "mtc = pd.read_csv(\"https://raw.githubusercontent.com/jefftwebb/is_4487_base/dd870389117d5b24eee7417d5378d80496555130/Labs/DataSets/megatelco_leave_survey.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtxOWvFlKzgE"
      },
      "source": [
        "## Clean the data\n",
        "\n",
        "Perform the cleaning from the previous labs:\n",
        "- Remove negative values of income and house\n",
        "- Remove absurdly large value of handset_price\n",
        "- Remove NAs\n",
        "- Change `college` to `yes` and `no`\n",
        "- Make string variables into categorical variables. We've been using `astype(\"categorical\")` to do that, but there is a better way when we also need to define an order among multiple levels.  This is important for plotting and for accurate modelling.\n",
        "\n",
        "Start by making `mtc_clean` an explicit copy.  This will avoid the warning you've been getting: \"A value is trying to be set on a copy of a slice from a DataFrame.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make copy\n",
        "mtc_clean = mtc.copy()"
      ],
      "metadata": {
        "id": "DnlmPgw4vpYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "-Qs5j2i23aG8"
      },
      "outputs": [],
      "source": [
        "# filter rows\n",
        "mtc_clean = mtc[(mtc['house'] > 0) & (mtc['income'] > 0) & (mtc['handset_price'] < 1000)]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove NAs\n",
        "mtc_clean = mtc_clean.dropna()"
      ],
      "metadata": {
        "id": "U0jC5mp0DHUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recode college\n",
        "mtc_clean['college'] = mtc_clean['college'].replace({'one': 'yes', 'zero': 'no'})"
      ],
      "metadata": {
        "id": "85LGAi-yzxmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the `pd.Categorical()` function to simultaneously make the string variables categorical and set the levels.  The syntax is:\n",
        "\n",
        "`data['column'] = pd.Categorical(data['column'],\n",
        "  categories = list,\n",
        "  ordered = True)`\n",
        "  \n",
        "  where \"list\" is the list of levels in order, such as:  `['small', 'medium', 'large']`. Without explicitly setting this order the default would be alphabetic:  large, medium, small.\n",
        "\n",
        "  Here's an example:"
      ],
      "metadata": {
        "id": "a5iP8B2Ww-QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert string to categorical variable\n",
        "mtc_clean['leave'] = pd.Categorical(mtc_clean['leave'],\n",
        "                                    categories = ['LEAVE', 'STAY'],\n",
        "                                    ordered = True)\n"
      ],
      "metadata": {
        "id": "cc-Z0X9QDIUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtc_clean['leave'].dtype"
      ],
      "metadata": {
        "id": "aUIkFZvcyw3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks good.  \n",
        "\n",
        "Go ahead and do a similar transformation on the remainder of categorical variables:\n",
        "\n",
        "- `reported_satisfaction`\n",
        "- `reported_usage_level`\n",
        "- `considering_change_of_plan`\n",
        "- `college`"
      ],
      "metadata": {
        "id": "lYH_QEYIzH26"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KXLvMcBK8Za"
      },
      "outputs": [],
      "source": [
        "# Your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uathUi6xfDPf"
      },
      "source": [
        "## Calculate the proportion of the majority class  \n",
        "What is the proportion of customers who churned? Note that `len(data)` (where \"data\" is your data frame) returns a count of the number of observations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ajdg2zO56Cf"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why should we care?\n",
        "\n",
        "The majority class in the target variable will serve as an important benchmark for model performance. Predicting the majority class is the simplest possible classifier. We'll call it the \"majority class classifier.\" It represents the best predictive guess you can make, in the absence of other information.  The accuracy of the majority class classifier is simply the proportion of the majority class in the data.\n",
        "\n",
        "Why is this?\n",
        "\n",
        "*Accuracy is defined as the proportion of correctly predicted labels. It is a commonly used error metric for evaluating classifier performance.*\n",
        "\n",
        "**Whatever later model we develop should have better accuracy than this performance benchmark.**"
      ],
      "metadata": {
        "id": "PBUEVVQz7G6n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoJLJMlceORN"
      },
      "source": [
        "## Fit a basic tree model\n",
        "\n",
        "Use just one variable, `income`. This is a very simple tree we'll call the \"money tree.\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vw085TGtcrB"
      },
      "outputs": [],
      "source": [
        "# Step 1:  Initialize model, specifying\n",
        "# 1. split criterion is entropy\n",
        "# 2. max_depth = 2\n",
        "\n",
        "money_tree = DecisionTreeClassifier(criterion = \"entropy\", max_depth = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of code:\n",
        "\n",
        "- `DecisionTreeClassifier()`: Creates an instance of the decision tree classifier from scikit-learn\n",
        "- `criterion=\"entropy\"`: Specifies the function to measure the quality of a split (entropy measures the impurity of the split)\n",
        "- `max_depth=2`: Limits the tree to a maximum depth of 2 levels, controlling complexity and preventing overfitting\n",
        "- Output: Returns a configured decision tree classifier object, ready to be fitted with data\n"
      ],
      "metadata": {
        "id": "k6SUiB_x-tvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create Decision Tree Classifer, specifying\n",
        "# 1. X (the predictor set) as income\n",
        "# 2. y (the target) as leave\n",
        "\n",
        "money_tree = money_tree.fit(X = mtc_clean[['income']],\n",
        "                            y = mtc_clean['leave'])\n"
      ],
      "metadata": {
        "id": "yzCaZ2Ud0Dmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of code:\n",
        "\n",
        "- `money_tree.fit()`: Trains the decision tree classifier on the provided data\n",
        "- `X = mtc_clean[['income']]`: Input feature (predictor), selecting only the `income` column *as a DataFrame* (note the double square brackets)\n",
        "- `y = mtc_clean['leave']`: Target variable, the `leave` column containing the class labels\n",
        "- Output: Returns the fitted decision tree model, now trained on the income data to predict customer churn\n",
        "\n",
        "Gemini prompt:  \"what is the difference between double and single square brackets in Pandas for slicing?\""
      ],
      "metadata": {
        "id": "UwkbiKj8-77f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Visualize the money tree model\n",
        "plot_tree(money_tree,\n",
        "          feature_names=[['income']],\n",
        "          class_names=['STAY', 'LEAVE'],\n",
        "          filled=True)\n"
      ],
      "metadata": {
        "id": "SBmTomoI0vqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of code:\n",
        "\n",
        "- `plot_tree()`: Function from scikit-learn to visualize the decision tree\n",
        "- `money_tree`: The fitted decision tree model to be visualized\n",
        "- `feature_names=[['income']]`: Labels the feature as `income` in the tree diagram\n",
        "- `class_names=['STAY', 'LEAVE']`: Specifies the names for the target classes in the visualization\n",
        "- `filled=True`: Colorizes the nodes based on the majority class at each node\n"
      ],
      "metadata": {
        "id": "cDiScO_z_Jr_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot is a bit confusing!  Here is an interpretive guide.\n",
        "\n",
        "1. **Root Node (Top)**:\n",
        "   - Split: income <= 99993.0\n",
        "   - Samples: 4994\n",
        "   - Initial prediction: LEAVE\n",
        "\n",
        "2. **Second Level**:\n",
        "   - Left Branch (income <= 20181.0):\n",
        "     - Samples: 3303\n",
        "     - Prediction: LEAVE\n",
        "   - Right Branch (20181.0 < income <= 159576.0):\n",
        "     - Samples: 1691\n",
        "     - Prediction: STAY\n",
        "\n",
        "3. **Third Level (Leaf Nodes)**:\n",
        "   - Far Left (income <= 20181.0):\n",
        "     - Samples: 8\n",
        "     - Prediction: LEAVE (high certainty, entropy = 0.0)\n",
        "   - Middle Left (20181.0 < income <= 99993.0):\n",
        "     - Samples: 3295\n",
        "     - Prediction: LEAVE (with uncertainty, entropy = 0.991)\n",
        "   - Middle Right (99993.0 < income <= 159576.0):\n",
        "     - Samples: 1680\n",
        "     - Prediction: STAY (with uncertainty, entropy = 0.977)\n",
        "   - Far Right (income > 159576.0):\n",
        "     - Samples: 11\n",
        "     - Prediction: STAY (high certainty, entropy = 0.0)\n",
        "\n"
      ],
      "metadata": {
        "id": "IbW4AjDb2jRr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSNfQKZA3jg2"
      },
      "source": [
        "## Check Accuracy\n",
        "\n",
        "What is the accuracy of the money_tree?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVOSIP8SeYg3"
      },
      "outputs": [],
      "source": [
        "# 1. Generate predictions from the model for the training data\n",
        "pred = money_tree.predict(X = mtc_clean[['income']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of code:\n",
        "\n",
        "- `money_tree.predict()`: Method to make predictions using the trained decision tree model\n",
        "- `X = mtc_clean[['income']]`: Input data for prediction, using only the `income` column from the DataFrame\n",
        "- Output: Returns an array of predicted class labels ('STAY' or 'LEAVE') for each row in the input data\n"
      ],
      "metadata": {
        "id": "jXLkeMZL_zl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Calculate accuracy as the proportion of correct predictions\n",
        "\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "3--rlxGz4Ijb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, this is better than the accuracy of the majority class classifier, which was our benchmark.  Success!\n",
        "\n",
        "Would a more complicated model have better performance measured in terms of accuracy?"
      ],
      "metadata": {
        "id": "72FK7HoX9I-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfitting\n",
        "\n",
        "Refit the tree, only this time leave out the `max_depth` argument.  This will allow the tree to fit as complicated a model as possible."
      ],
      "metadata": {
        "id": "ZMR3whx_5GlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "aAJoimRw5MqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whoa!\n",
        "\n",
        "What is the accuracy of this model?"
      ],
      "metadata": {
        "id": "0Wnnf3Wm6AyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here"
      ],
      "metadata": {
        "id": "3iTvS_l95__u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Killing it!"
      ],
      "metadata": {
        "id": "kKJ0uq8N61eP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validation\n",
        "\n",
        "Or:  maybe not.  Will you get promoted or ... fired?\n",
        "\n",
        "This model is excessively complicated.  It has figured out how to classify the target perfectly *in the training data*. It has essentially just memorize the training data.  However, when it encounters new data **it will suck**. That's because new data will have patterns that were not in the training data (this is the nature of sampling) and the overfit model will get badly confused.\n",
        "\n",
        "To demonstrate this we will use cross-validation.\n",
        "\n",
        "The simplest version of cross-validation uses a training set and a testing or validation set. (This is called the validation set method.) Simply, we divide the data that we have into two parts: 80% goes into the training set and 20% into the testing set. (80/20 is a common choice.) That division is done randomly using the `sample()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "7ynhMyZR7BuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# divide mtc_clean into train and test\n",
        "train = mtc_clean.sample(frac=0.8, random_state=200) # 80% of data for training\n",
        "test = mtc_clean.drop(train.index) # the remaining 20%\n"
      ],
      "metadata": {
        "id": "CxdV8oWo9OrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`random_state` is a seed that ensures the same split when set to 200 (an arbitrary choice). This will make our results comparable."
      ],
      "metadata": {
        "id": "Nyj6Q2jF96wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "Jpk4epVa911m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "u8qGHvLq-Ncj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross validation procedure is to create the model using the train data and then evaluate it--that is, get predictions--using the test data. Accuracy of the model is therefore calculated using the test data. This way, we get an accurate picture of how the model will perform in the wild, with new data.\n",
        "\n",
        "Make sure to leave out the `max_depth` argument."
      ],
      "metadata": {
        "id": "W6EjdejC-R2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifier.  Leave out max_depth\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "4UOfGsNE_uIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model using train\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "dpixS1YF-eEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using test\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "7BW9raTa-hbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model accuracy on the test set\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "kIRct2Hs--fL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better or worse than the simpler model?  \n",
        "\n",
        "Let's explore this further.  More complicated models are good--up to a point.  Choose a `max_depth` argument greater than 2 and see if you can improve on the simple model's accuracy without getting too complex and overfitting."
      ],
      "metadata": {
        "id": "w7hthal9AIPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifier--chose a max_depth > 2\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "TZ6VYT6KAki1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model using train\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "f-1C5r8FAoF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using test\n",
        "# Your code goes here"
      ],
      "metadata": {
        "id": "nuDDBpWeAlfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model accuracy on the test set\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "d2tvYUxPAyEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional predictors\n",
        "\n",
        "Pick one additional variable to use as a predictor--one that you think is a driver of churn at MegaTelCo, based on your EDA.\n",
        "\n",
        "Refit the model using your best performing `max_depth` setting, with `income` and your chosen second predictor.\n",
        "\n",
        "How does this model perform on the test set?\n",
        "\n",
        "Adding a predictor makes for a more complicated model.  But complicated is good -- as long as it does not tip over into overfitting."
      ],
      "metadata": {
        "id": "OnlGtiDCwNJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the classifier--chose a max_depth > 2\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "aKDd5ZEOxX7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model using train\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "xjymduwoxdQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using test\n",
        "# Your code goes here"
      ],
      "metadata": {
        "id": "n-02crspxgid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model accuracy on the test set\n",
        "# Your code goes here\n"
      ],
      "metadata": {
        "id": "XJSt7Vn_xjfC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}